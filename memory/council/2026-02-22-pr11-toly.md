# Council Review: toly — PR #11
_Reviewed on 2026-02-22 03:52 UTC_

# Council Review: solana_monitor.py Error Handling

**Toly's Take:** This is solid defensive engineering, but there's a throughput problem buried in here that we need to address.

## Throughput Analysis

The PR adds error handling around JSON parsing and API calls — good. But I'm seeing sequential blocking that kills monitoring efficiency:

```python
result = run_shell([
    "curl", "-sS", "-X", "POST", rpc_url,
    "-H", "Content-Type: application/json",
    "-d", payload
])
```

This is blocking per-wallet. If you're monitoring 50 wallets, that's 50 sequential curl calls. On Solana's mainnet with occasional RPC slowness, you're looking at potential timeouts stacking up. The error handling is there, but the architecture isn't built for parallel monitoring sweeps.

**Missing:** Async calls or concurrent request batching. This should be using `asyncio` + batch JSON-RPC requests (Solana supports it), not sequential blocking I/O.

## Parallelism Audit

The snapshot loading/saving is fine — that's IO you can't parallelize. But the wallet monitoring loop? That needs to run concurrent API calls per wallet, not sequential.

Current flow:
- Load snapshot (OK)
- Loop over wallets
  - Call API (BLOCKING)
  - Parse JSON (fast)
  - Compare state (fast)

Better flow:
- Load snapshot
- **Batch API calls to RPC** (one round-trip, multiple wallets)
- Parse results concurrently
- Compare in parallel

This matters on Solana because:
1. RPC endpoints rate-limit sequential connections
2. You're wasting slot time between calls
3. Validator epochs move while you're waiting for JSON

## Crypto-Native Angle

Error handling here is trustless-friendly — you're not silently accepting bad data. That's good. But you're over-trusting the RPC endpoint with sequential requests. On a real adversarial network, a slow/malicious RPC can DOS your monitoring by making each call slow.

**Batching + timeouts** is the Solana-native pattern. Use `getProgramAccounts` or batch the JSON-RPC calls. Don't make 50 individual HTTP requests.

## Code Quality Notes

- Error messages are good — context about which token/API failed is useful
- Fallback behavior (continue monitoring) is correct
- The try-except around JSON parsing is necessary
- **BUT:** You're catching exceptions after the fact. Better to validate structure upfront.

Example: Before parsing, check if `result["stdout"]` is empty or null. Saves parsing overhead.

## The Real Issue

This PR treats error handling as a patch. It is — a good one. But it doesn't address the underlying architecture problem: **you're doing I/O sequentially in a system that should be monitoring multiple wallets concurrently.**

With the current approach, adding error handling makes the code more robust, but not faster. And on Solana, throughput IS reliability — if your monitoring takes 30s per sweep instead of 3s, you miss price movements and balance changes.

## Toly's Call

The error handling itself is solid. But shipping this without addressing parallelism is leaving money on the table (literally — missed monitoring windows = missed arbitrage detection).

**Fix required:**
1. Migrate to async/await with `aiohttp` or `solders` library
2. Batch JSON-RPC calls (getProgramAccounts or multiCall pattern)
3. Keep the error handling — it's good — but wrap concurrent calls

This is a REVISE, not a reject. The code works. But we can do better in 2-3 hours.

VOTE: REVISE
